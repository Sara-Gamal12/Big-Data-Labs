#1. First of all, start by cleaning the workspace and setting the working directory.
rm(list = ls())
setwd("C:\Users\Sara\me\4th\big data\Big Data Labs\Big-Data-Labs\Lab 6 - Descriptive Analysis\Clustering")
setwd("C:/Users/Sara/me/4th/big data/Big Data Labs/Big-Data-Labs/Lab 6 - Descriptive Analysis/Clustering")
#2. Import the dataset clustering_data.csv into a data frame and plot the points.
data <- read.csv("clustering_data.csv", header = TRUE)
plot(data, main = "Scatter plot of clustering data", pch = 19)
#3. Perform a k-means clustering on the data with 10 clusters and 15 iterations.
kmeans_result_10 <- kmeans(data, centers = 10, iter.max = 15)
#4. Print the cluster centroids.
print(kmeans_result_10$centers)
#5. Plot data such that each point is colored according to its cluster.
plot(data, col = kmeans_result_10$cluster, pch = 19, main = "K-means Clustering with 10 Clusters")
#5. Plot data such that each point is colored according to its cluster.
plot(data, col = kmeans_result_10$cluster, pch = 19, main = "K-means Clustering with 10 Clusters")
#6. Overlay the cluster centroids on the above plot. Plot them as solid filled triangles.
points(kmeans_result_10$centers, col = 1:10, pch = 17, cex = 2)
#6. Overlay the cluster centroids on the above plot. Plot them as solid filled triangles.
points(kmeans_result_10$centers, col = 1:10, pch = 17, cex = 2)
#8. Now, determine the best number of clusters by two different ways.
#-- method 1->elbow method
wss <- numeric(15)
for (k in 1:15) {
wss[k] <- sum(kmeans(data, centers = k, nstart = 10)$withinss)
}
plot(1:15, wss, type = "b", pch = 19, frame = FALSE,
xlab = "Number of Clusters",
ylab = "Total Within Sum of Squares",
main = "Elbow Method")
##clear from graph that elbow is at 3 clusters
##--method 2->Silhouette Method
library(cluster)
avg_sil <- numeric(15)
for (k in 2:15) {
km <- kmeans(data, centers = k, nstart = 10)
ss <- silhouette(km$cluster, dist(data))
avg_sil[k] <- mean(ss[, 3])
}
plot(2:15, avg_sil[2:15], type = "b", pch = 19,
xlab = "Number of Clusters",
ylab = "Average Silhouette Width",
main = "Silhouette Method")
#9. Tabulate the voting results.
elbow_best <- which(diff(diff(wss)) == min(diff(diff(wss)))) + 1
elbow_best
sil_best <- which.max(avg_sil)
vote_table <- data.frame(Method = c("Elbow", "Silhouette"),
Best_K = c(elbow_best, sil_best))
print(vote_table)
#9. Tabulate the voting results.
elbow_best <- which(diff(diff(wss)) == min(diff(diff(wss)))) + 1
sil_best <- which.max(avg_sil)
vote_table <- data.frame(Method = c("Elbow", "Silhouette"),
Best_K = c(elbow_best, sil_best))
print(vote_table)
#8. Now, determine the best number of clusters by two different ways.
#-- method 1->elbow method
wss <- numeric(15)
for (k in 1:15) {
wss[k] <- sum(kmeans(data, centers = k, nstart = 10)$withinss)
}
plot(1:15, wss, type = "b", pch = 19, frame = FALSE,
xlab = "Number of Clusters",
ylab = "Total Within Sum of Squares",
main = "Elbow Method")
#8. Now, determine the best number of clusters by two different ways.
#-- method 1
mydata <- dfm.data
wss <- (nrow(data)-1)*sum(apply(data,2,var))
#8. Now, determine the best number of clusters by two different ways.
#-- method 1
wss <- (nrow(data)-1)*sum(apply(data,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(data, centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
##--method 2
nc <- NbClust(data, min.nc=2, max.nc=15, method="kmeans")
library(rattle.data)
library(NbClust)
library(cluster)
library(HSAUR)
##Sara Gamal     9210455
##Eman Ibrahim   9210265
install(rattle.data)
##Sara Gamal     9210455
##Eman Ibrahim   9210265
install.packages("rattle.data")
install.packages("NbClust")
install.packages("HSAUR")
##Sara Gamal     9210455
##Eman Ibrahim   9210265
#install.packages("rattle.data")
#install.packages("NbClust")
#install.packages("HSAUR")
library(rattle.data)
library(NbClust)
library(cluster)
library(HSAUR)
##--method 2
nc <- NbClust(data, min.nc=2, max.nc=15, method="kmeans")
#9. Tabulate the voting results.
elbow_best <- which(diff(diff(wss)) == min(diff(diff(wss)))) + 1
#9. Tabulate the voting results.
table(nc$Best.n[1,])
##its clear the 3 is best number of clusters
#10. Perform a k-means clustering on the data with the best number of clusters chosen in step 3. Choose an appropriate number of iterations.
best_k <- sil_best
kmeans_best <- kmeans(data, centers = best_k, iter.max = 20)
#11. Repeat (4, 5, 6) for the new number of clusters.
print(kmeans_best$centers)
plot(data, col = kmeans_best$cluster, pch = 19, main = "K-means Clustering with 3 Clusters")
points(kmeans_best$centers, col = 1:10, pch = 17, cex = 2)
install.packages("png")
#1. First of all, start by cleaning the workspace and setting the working directory.
rm(list = ls())
setwd("C:/Users/Sara/me/4th/big data/Big Data Labs/Big-Data-Labs/Lab 6 - Descriptive Analysis/Clustering")
library(png)
img <- readPNG("bird_small.png")
img_dim <- dim(img)
rows <- img_dim[1]
cols <- img_dim[2]
r <- as.vector(img[,,1])
g <- as.vector(img[,,2])
b <- as.vector(img[,,3])
df <- data.frame(R = r, G = g, B = b)
#4. Perform a k-means clustering on the data with 16 clusters and 15 iterations.
kmeans_result <- kmeans(df, centers = 16, iter.max = 15)
#5.  Show the cluster each point belongs to.
head(kmeans_result$cluster)
#6. Display the 16 centroids of the clusters. What do these centroids represent?
centroids <- kmeans_result$centers
print(centroids)
#7. Assign each pixel to the centroid of its cluster.
df_compressed <- centroids[kmeans_result$cluster, ]
#7. Assign each pixel to the centroid of its cluster.
df_compressed <- centroids[kmeans_result$cluster, ]
#8. Reshape the data frame again to a 3-dimensional form.
img_dim <- dim(img)
rows <- img_dim[1]
cols <- img_dim[2]
img_compressed <- array(0, dim = c(rows, cols, 3))
img_compressed[,,1] <- matrix(df_compressed$R, nrow = rows, byrow = FALSE)
img_compressed[,,2] <- matrix(df_compressed$G, nrow = rows, byrow = FALSE)
img_compressed[,,3] <- matrix(df_compressed$B, nrow = rows, byrow = FALSE)
#8. Reshape the data frame again to a 3-dimensional form.
img_dim <- dim(img)
rows <- img_dim[1]
cols <- img_dim[2]
img_compressed <- array(0, dim = c(rows, cols, 3))
img_compressed[,,1] <- matrix(df_compressed$R, nrow = rows, byrow = FALSE)
img_compressed[,,1] <- matrix(df_compressed$R, nrow = rows, byrow = FALSE)
img_compressed[,,1] <- matrix(df_compressed[, 1], nrow = rows, byrow = FALSE)  # R
img_compressed[,,2] <- matrix(df_compressed[, 2], nrow = rows, byrow = FALSE)  # G
img_compressed[,,3] <- matrix(df_compressed[, 3], nrow = rows, byrow = FALSE)  # B
#9. Write the compressed image in a file named compressed.png. Now check its size.
writePNG(img_compressed, target = "compressed.png")
#7. Assign each pixel to the centroid of its cluster.
df_compressed <- centroids[kmeans_result$cluster, ]
library(png)
#1. First of all, start by cleaning the workspace and setting the working directory.
rm(list = ls())
setwd("C:/Users/Sara/me/4th/big data/Big Data Labs/Big-Data-Labs/Lab 6 - Descriptive Analysis/Clustering")
img <- readPNG("bird_small.png")
r <- as.vector(img[,,1])
g <- as.vector(img[,,2])
b <- as.vector(img[,,3])
df <- data.frame(R = r, G = g, B = b)
#4. Perform a k-means clustering on the data with 16 clusters and 15 iterations.
kmeans_result <- kmeans(df, centers = 16, iter.max = 15)
#5.  Show the cluster each point belongs to.
head(kmeans_result$cluster)
